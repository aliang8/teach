{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ishika/envs/teach/lib/python3.7/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "\n",
    "from teach.dataset.definitions import Definitions\n",
    "from teach.dataset.dataset import Dataset\n",
    "from teach.dataset.actions import Action_Keyboard, Action_ObjectInteraction\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from teach.dataset.dataset import Dataset\n",
    "from teach.dataset.definitions import Definitions\n",
    "from teach.logger import create_logger\n",
    "from teach.simulators import simulator_factory\n",
    "from teach.utils import get_state_changes, reduce_float_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/anthony/teach/games/train/\"\n",
    "image_dir = \"/data/anthony/teach/images/train/\"\n",
    "definitions = Definitions(version=\"2.0\")\n",
    "f = os.path.join(data_dir, \"games/train/7d2a79f43e605c36_1657.game.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4de84f3acfac78cf_c9bf.game.json\n",
      "9a95158f1217214e_c5d8.game.json\n",
      "cebbfb71c4d31533_6ddd.game.json\n",
      "66f67a99f785f66f_3bf9.game.json\n",
      "f560dc436bf42c07_201d.game.json\n",
      "667bac1b28cdf862_1575.game.json\n",
      "eb1345f71f2a0473_f82e.game.json\n",
      "fa548a83b3cecc52_3cac.game.json\n",
      "471f25bcb3c45f09_55db.game.json\n",
      "f51cb64eb58334ca_55c9.game.json\n",
      "230ccbf346fbf67b_0d42.game.json\n",
      "ca504a258d1704b5_343b.game.json\n",
      "19f512eab5786ae2_fbce.game.json\n",
      "c602e4be2e9a821f_d829.game.json\n",
      "a45760a86b224b35_1261.game.json\n",
      "b58d8beaf2e79628_cea6.game.json\n",
      "275be6a3865feb91_bc42.game.json\n",
      "d94cfb735340ee41_66d5.game.json\n",
      "df895243ac1dc147_f5a1.game.json\n",
      "cc9cb24928831777_2853.game.json\n",
      "e45c32d4b768e21e_d0cd.game.json\n",
      "b8a576d1413c448a_b995.game.json\n",
      "470f9c054b38bb8e_2c0e.game.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4d494140b94b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# print(interactions[idx].commander_obs.size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-4d494140b94b>\u001b[0m in \u001b[0;36mload\u001b[0;34m(data_dir, image_dir)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;31m# print(commander_obs[time_start].size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"driver\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mdriver_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# print(driver_obs[time_start].size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m          \u001b[0;31m### add other frames if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ishika/envs/teach/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2962\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## loading all data + obs frames and returning a merged dict\n",
    "\n",
    "def load(data_dir, image_dir):\n",
    "    for game_file in os.listdir(data_dir):\n",
    "        # print(game_file)\n",
    "        f = os.path.join(data_dir, game_file)\n",
    "        game = Dataset.import_json(f, version=\"2.0\")\n",
    "        interactions = game.tasks[0].episodes[0].interactions\n",
    "\n",
    "        commander_obs = {}\n",
    "        driver_obs = {}\n",
    "        game_image_dir = os.path.join(image_dir, game_file.split('.')[0])\n",
    "        for img_file in os.listdir(game_image_dir):\n",
    "            # print(img_file)\n",
    "            f = os.path.join(game_image_dir, img_file)\n",
    "            # print(f)\n",
    "            time_start = '.'.join(img_file.split('.')[2:4])\n",
    "            if img_file.split('.')[0]==\"commander\":\n",
    "                commander_obs[time_start] = Image.open(f)\n",
    "                # print(commander_obs[time_start].size)\n",
    "            if img_file.split('.')[0]==\"driver\":\n",
    "                driver_obs[time_start] = Image.open(f)\n",
    "                # print(driver_obs[time_start].size)\n",
    "            else:          ### add other frames if needed\n",
    "                # print(\"pass\")\n",
    "                pass\n",
    "        for idx in range(len(interactions)):\n",
    "            time_start = str(interactions[idx].time_start)\n",
    "            interactions[idx].commander_obs = commander_obs[time_start]\n",
    "            interactions[idx].driver_obs = driver_obs[time_start]\n",
    "            # print(interactions[idx].commander_obs.size)\n",
    "    game.tasks[0].episodes[0].interactions = interactions\n",
    "    return game\n",
    "# load(data_dir, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2b802f1e534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maction_id_to_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_actions_id2info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEpisodePlay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulator_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlive_feeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_logger' is not defined"
     ]
    }
   ],
   "source": [
    "## helper functions\n",
    "action_id_to_info = definitions.map_actions_id2info\n",
    "\n",
    "class EpisodePlay:\n",
    "    def __init__(self, simulator_name, live_feeds, episode=None):\n",
    "        \"\"\"\n",
    "        Initialize a simulator to use.\n",
    "        live_feeds: list of string names for camera feeds whose data we should save during replay\n",
    "        simulator_name: name of simulator that is registered in simulator_factory\n",
    "        \"\"\"\n",
    "        self.simulator = simulator_factory.factory.create(simulator_name, web_window_size=900)\n",
    "        self.simulator_name = simulator_name\n",
    "        if episode: \n",
    "            self.episode = episode\n",
    "\n",
    "        for name_feed in live_feeds:\n",
    "            if name_feed not in self.simulator.live_feeds:\n",
    "                self.simulator.live_feeds.add(name_feed)\n",
    "\n",
    "        # State data.\n",
    "        self.task = self.task_params = self.episode = None\n",
    "\n",
    "    def set_episode_by_fn_and_idx(self, game_fn, task_idx, episode_idx, episode):\n",
    "        \"\"\"\n",
    "        Read in an episode from file.\n",
    "        game_fn: the game logfile to read\n",
    "        task_idx: the task in the game logfile to read\n",
    "        episode_idx: the episode in the task metadata to read\n",
    "        \"\"\"\n",
    "\n",
    "        structured_log = episode\n",
    "        task = structured_log.tasks[task_idx]\n",
    "        self.task = task.task_name\n",
    "        self.task_params = task.task_params\n",
    "        self.episode = task.episodes[episode_idx]\n",
    "\n",
    "    def play_episode(\n",
    "        self,\n",
    "        obs_dir=None,\n",
    "        realtime=False,\n",
    "        force_replay=False,\n",
    "        write_frames=False,\n",
    "        write_states=False,\n",
    "        write_episode_progress=False,\n",
    "        turn_on_lights=False,\n",
    "        task=None,\n",
    "        shutdown_on_finish=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Play back the interactions in an episode.\n",
    "        obs_dir: the directory to write observation files; if None, skips writing raw observation data.\n",
    "        realtime: if True, play back episode with delays between actions based on user times.\n",
    "        force_replay: if False, skips playback if the obs_dir is non-emtpy.\n",
    "        write_frames: if True, frames will be written out at every time step.\n",
    "        write_states: if True, states will be written out at every time step.\n",
    "        write_episode_progress: if True, episode progress will be written out at every time step.\n",
    "        turn_on_lights: if True, will turn on the lights even if the game had them off.\n",
    "        \"\"\"\n",
    "        if not force_replay and obs_dir is not None and os.path.isdir(obs_dir) and len(os.listdir(obs_dir)) > 0:\n",
    "            logger.warn(\"play_episode skipping playback in non-empty dir '%s'\" % obs_dir)\n",
    "            return False, False\n",
    "\n",
    "        api_success, init_state = self._set_up_new_episode(obs_dir, turn_on_lights, task)\n",
    "\n",
    "        target_object_active = False\n",
    "        for idx in range(len(self.episode.interactions)):\n",
    "            api_success, target_object_active = self._play_single_interaction(\n",
    "                api_success,\n",
    "                idx,\n",
    "                init_state,\n",
    "                obs_dir,\n",
    "                realtime,\n",
    "                target_object_active,\n",
    "                write_episode_progress,\n",
    "                write_frames,\n",
    "                write_states,\n",
    "            )\n",
    "        self._write_last_states_and_frames(init_state, obs_dir, target_object_active, write_frames, write_states)\n",
    "\n",
    "        _, task_success, _, _, _ = self.simulator.check_episode_progress(self.simulator.current_task)\n",
    "\n",
    "        if shutdown_on_finish:\n",
    "            self.simulator.shutdown_simulator()\n",
    "            logger.info(\n",
    "                \"Episode ended, took %d steps; api success=%d; task success=%d\"\n",
    "                % (len(self.episode.interactions), int(api_success), int(task_success))\n",
    "            )\n",
    "\n",
    "        return api_success, task_success\n",
    "\n",
    "    def stitch_episode_video(self, obs_dir, font_fn, force_replay=False):\n",
    "        \"\"\"\n",
    "        Stitch together a video of the episode for demo/inspection purposes.\n",
    "        obs_dir - the observations to read in\n",
    "        force_replay: if False, skips playback if the [obs_dir]/video is non-emtpy.\n",
    "        \"\"\"\n",
    "        out_dir = os.path.join(obs_dir, \"video\")\n",
    "        if not force_replay and os.path.isdir(out_dir) and len(os.listdir(out_dir)) > 0:\n",
    "            logger.warn(\"stitch_episode_video skipping video stitch in non-empty dir '%s'\" % out_dir)\n",
    "            return\n",
    "\n",
    "        # Assemble frames to be stitched together and determine order.\n",
    "        frame_fns = glob.glob(os.path.join(obs_dir, \"*.j*\"))  # 'jpeg', 'json'\n",
    "        timestamps_to_fns = {}\n",
    "        for fn in frame_fns:\n",
    "            t = \".\".join(fn.split(\".\")[2:-1])\n",
    "            if t not in timestamps_to_fns:\n",
    "                timestamps_to_fns[t] = []\n",
    "            timestamps_to_fns[t].append(fn)\n",
    "\n",
    "        # Create the frames of the video. They are a 4 panel showing driver, commander, target object, and\n",
    "        # target object seg mask at each timestep.\n",
    "        frame_border = 50  # pixels\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        frame = ref_im = None\n",
    "        for fn in frame_fns:\n",
    "            if fn.split(\".\")[-1] == \"jpeg\":\n",
    "                ref_im = Image.open(fn)\n",
    "                frame = Image.new(\n",
    "                    \"RGB\",\n",
    "                    (frame_border * 2 + ref_im.width * 4, frame_border * 2 + ref_im.height * 2),\n",
    "                )\n",
    "                break\n",
    "        frame_layout = {\n",
    "            \"driver.frame\": (0, 0),\n",
    "            \"commander.frame\": (1, 0),\n",
    "            \"targetobject.frame\": (0, 1),\n",
    "            \"targetobject.mask\": (1, 1),\n",
    "            \"text\": (2, 0),\n",
    "            \"bottomright\": (4, 2),\n",
    "        }\n",
    "\n",
    "        frame_idx = 0\n",
    "        logger.info(\"Iterating through frames to assemble video tiles...\")\n",
    "        for t in tqdm.tqdm(sorted(timestamps_to_fns, key=lambda x: float(x) if x and x != \"end\" else float(\"inf\"))):\n",
    "            for fn in timestamps_to_fns[t]:\n",
    "                frame_type = \".\".join(fn.split(\"/\")[-1].split(\".\")[:2])\n",
    "                if frame_type in frame_layout:  # visual observation\n",
    "                    im = Image.open(fn)\n",
    "                    frame.paste(\n",
    "                        im,\n",
    "                        (\n",
    "                            frame_border + ref_im.width * frame_layout[frame_type][0],\n",
    "                            frame_border + ref_im.height * frame_layout[frame_type][1],\n",
    "                        ),\n",
    "                    )\n",
    "                else:  # text observation\n",
    "                    with open(fn, \"r\") as f:\n",
    "                        contents = json.load(f)\n",
    "                    draw = ImageDraw.Draw(frame)\n",
    "                    draw.rectangle(\n",
    "                        (\n",
    "                            (\n",
    "                                frame_border + ref_im.width * frame_layout[\"text\"][0],\n",
    "                                frame_border + ref_im.height * frame_layout[\"text\"][1],\n",
    "                            ),\n",
    "                            (\n",
    "                                frame_border + ref_im.width * frame_layout[\"bottomright\"][0],\n",
    "                                frame_border + ref_im.height * frame_layout[\"bottomright\"][1],\n",
    "                            ),\n",
    "                        ),\n",
    "                        fill=\"black\",\n",
    "                    )\n",
    "                    font_size = 64\n",
    "                    font = ImageFont.truetype(font_fn, font_size)\n",
    "                    s = \"%s: %s\" % (frame_type, json.dumps(contents))\n",
    "                    line_idx = 0\n",
    "                    chars_per_line = 44\n",
    "                    while len(s) > 0:\n",
    "                        draw.text(\n",
    "                            (\n",
    "                                frame_border + ref_im.width * frame_layout[\"text\"][0] + 5,\n",
    "                                frame_border + ref_im.height * frame_layout[\"text\"][1] + (font_size + 5) * line_idx,\n",
    "                            ),\n",
    "                            s[: min(len(s), chars_per_line)],\n",
    "                            (255, 255, 255),\n",
    "                            font=font,\n",
    "                        )\n",
    "                        s = s[min(len(s), chars_per_line) :]\n",
    "                        line_idx += 1\n",
    "            frame.save(os.path.join(out_dir, \"%05d.jpeg\" % frame_idx), format=\"jpeg\")\n",
    "            frame_idx += 1\n",
    "        logger.info(\"... done; wrote %d assembled frames\" % frame_idx)\n",
    "\n",
    "        if frame_idx > 0:\n",
    "            cmd = (\n",
    "                'ffmpeg -r 1 -start_number 0 -i \"'\n",
    "                + out_dir\n",
    "                + '/%05d.jpeg\" -c:v libx264 -vf \"fps=25,format=yuv420p\" '\n",
    "                + os.path.join(out_dir, \"video.mp4\")\n",
    "            )\n",
    "            logger.info(\"Executing: \", cmd)\n",
    "            os.system(cmd)\n",
    "            logger.info(\"... done\")\n",
    "        else:\n",
    "            logger.warn(\"no frames extracted to stich video for %s\" % out_dir)\n",
    "\n",
    "    def write_progress(self, frame_idx, obs_dir):\n",
    "        progress_check_output = self.simulator.current_task.check_episode_progress(\n",
    "            self.simulator.get_objects(self.simulator.controller.last_event), self.simulator\n",
    "        )\n",
    "        with open(\n",
    "            os.path.join(\n",
    "                obs_dir,\n",
    "                \"progress_check_output.%s.pkl\" % (frame_idx,),\n",
    "            ),\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(progress_check_output, f)\n",
    "\n",
    "    def write_cur_state(self, frame_idx, obs_dir, init_state):\n",
    "        cur_state = reduce_float_precision(self.simulator.get_current_state().to_dict())\n",
    "        state_diff = get_state_changes(init_state, cur_state)\n",
    "        with open(\n",
    "            os.path.join(\n",
    "                obs_dir,\n",
    "                \"statediff.%s.json\" % (frame_idx,),\n",
    "            ),\n",
    "            \"w\",\n",
    "        ) as f:\n",
    "            json.dump(state_diff, f)\n",
    "\n",
    "    def write_frames(self, frame_idx, obs_dir, target_object_active):\n",
    "        frames = self.simulator.get_latest_images()\n",
    "        self._write_frame(\n",
    "            frames[\"ego\"],\n",
    "            os.path.join(\n",
    "                obs_dir,\n",
    "                \"driver.frame.%s.jpeg\" % frame_idx,\n",
    "            ),\n",
    "        )\n",
    "        self._write_frame(\n",
    "            frames[\"allo\"],\n",
    "            os.path.join(\n",
    "                obs_dir,\n",
    "                \"commander.frame.%s.jpeg\" % frame_idx,\n",
    "            ),\n",
    "        )\n",
    "        self._write_frame(\n",
    "            frames[\"targetobject\"] if target_object_active else np.zeros_like(frames[\"targetobject\"]),\n",
    "            os.path.join(\n",
    "                obs_dir,\n",
    "                \"targetobject.frame.%s.jpeg\" % frame_idx,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def _play_single_interaction(\n",
    "        self,\n",
    "        api_success,\n",
    "        idx,\n",
    "        init_state,\n",
    "        obs_dir,\n",
    "        realtime,\n",
    "        target_object_active,\n",
    "        write_episode_progress,\n",
    "        write_frames,\n",
    "        write_states,\n",
    "    ):\n",
    "\n",
    "        frame_idx = str(self.episode.interactions[idx].time_start)\n",
    "\n",
    "        # if obs_dir is not None and write_states:\n",
    "        #     self.write_cur_state(frame_idx, obs_dir, init_state)\n",
    "\n",
    "        # if obs_dir is not None and write_frames:\n",
    "        #     self.write_frames(frame_idx, obs_dir, target_object_active)\n",
    "\n",
    "        # if realtime:\n",
    "        #     self._wait_for_real_time(idx)\n",
    "\n",
    "        action_definition = action_id_to_info[self.episode.interactions[idx].action.action_id]\n",
    "        logger.debug(\"taking action <<%s, %s>>\" % (action_definition[\"action_type\"], action_definition[\"action_name\"]))\n",
    "        logged_success = self.episode.interactions[idx].action.success\n",
    "        interact_oid = (\n",
    "            self.episode.interactions[idx].action.oid\n",
    "            if action_definition[\"action_type\"] == \"ObjectInteraction\"\n",
    "            else None\n",
    "        )\n",
    "        if logged_success == 1:\n",
    "            self._add_interaction(idx, interact_oid, logged_success)\n",
    "\n",
    "            api_success = api_success & (1 == self.episode.interactions[idx].action.success)\n",
    "\n",
    "            if obs_dir is not None and write_frames:\n",
    "                if action_definition[\"action_type\"] == \"Keyboard\":\n",
    "                    self._write_keyboard_frame(idx, obs_dir)\n",
    "\n",
    "            if obs_dir is not None and write_frames:\n",
    "                if action_definition[\"action_type\"] == \"ProgressCheck\":\n",
    "                    target_object_active = self._write_progress_check(\n",
    "                        idx, obs_dir, action_definition, target_object_active\n",
    "                    )\n",
    "        if obs_dir is not None and write_episode_progress:\n",
    "            self.write_progress(frame_idx, obs_dir)\n",
    "        return api_success, target_object_active\n",
    "\n",
    "    def _add_interaction(self, idx, interact_oid, logged_success):\n",
    "        self.simulator.add_interaction(self.episode.interactions[idx])\n",
    "        if self.episode.interactions[idx].action.success != logged_success:\n",
    "            logger.debug(\n",
    "                \"... action success logged %d != %d of action just taken\"\n",
    "                % (logged_success, self.episode.interactions[idx].action.success)\n",
    "            )\n",
    "        # If oid was interacted with in orig, but action failed on replay or the wrong oid was interacted when using\n",
    "        # the (x, y) coords given (e.g., because objects can jitter with PhysX but shouldn't be\n",
    "        # out of frame in most cases), try to just get a correct oid click directly.\n",
    "        if interact_oid is not None and (\n",
    "            (logged_success and not self.episode.interactions[idx].action.success)\n",
    "            or interact_oid != self.episode.interactions[idx].action.oid\n",
    "        ):\n",
    "            # Next, override the provided user (x, y) with a randomly selected mask point (x*, y*) on the object.\n",
    "            mask_frame = self.simulator.get_target_object_seg_mask(interact_oid)[\"mask\"]\n",
    "            mask_points = np.where(mask_frame == 1)[:2]\n",
    "            if len(mask_points[0]) > 0:  # if any part of the object is visible in the frame, pick a point on it\n",
    "                rpoint_idx = np.random.randint(0, len(mask_points[0]))\n",
    "                override_interaction = copy.deepcopy(self.episode.interactions[idx])\n",
    "                override_interaction.action.x = mask_points[1][rpoint_idx] / self.simulator.web_window_size\n",
    "                override_interaction.action.y = mask_points[0][rpoint_idx] / self.simulator.web_window_size\n",
    "                logger.info(\"... override interaction %s\" % override_interaction)  # DEBUG\n",
    "                self.simulator.add_interaction(override_interaction)\n",
    "                if self.episode.interactions[idx].action.success != logged_success:\n",
    "                    logger.info(\n",
    "                        \"...... action success logged %d != %d of override action with oid %s just taken\"\n",
    "                        % (\n",
    "                            logged_success,\n",
    "                            self.episode.interactions[idx].action.success,\n",
    "                            interact_oid,\n",
    "                        )\n",
    "                    )\n",
    "            else:  # Really nasty, object isn't even visible. Try to take the action directly.\n",
    "                logger.info(\"... override interaction with oid %s\" % interact_oid)\n",
    "                cur_objs = self.simulator.get_objects()\n",
    "                logger.info(\n",
    "                    \"Cur objs (ID, visible): %s \" % str([(obj[\"objectId\"], obj[\"visible\"]) for obj in cur_objs])\n",
    "                )\n",
    "                self.simulator.add_interaction(self.episode.interactions[idx], on_oid=interact_oid, force=True)\n",
    "                if self.episode.interactions[idx].action.success != logged_success:\n",
    "                    logger.info(\n",
    "                        \"..... action success logged %d != %d of override action just taken\"\n",
    "                        % (logged_success, self.episode.interactions[idx].action.success)\n",
    "                    )\n",
    "\n",
    "    def _set_up_new_episode(self, obs_dir, turn_on_lights, task=None):\n",
    "        api_success = True\n",
    "        self.simulator.reset_stored_data()\n",
    "        logger.info(\"Starting episode...\")\n",
    "        self.simulator.start_new_episode(\n",
    "            world=self.episode.world,\n",
    "            world_type=self.episode.world_type,\n",
    "            commander_embodied=True if self.episode.commander_embodied == \"True\" else False,\n",
    "        )\n",
    "        logger.info(\"... done\")\n",
    "\n",
    "        logger.info(\"Loading initial scene state...\")\n",
    "        _, s = self.simulator.load_scene_state(init_state=self.episode.initial_state)\n",
    "        api_success = api_success & s\n",
    "        logger.info(\"... done\")\n",
    "\n",
    "        if task is not None:\n",
    "            logger.info(\"Setting to custom task %s\" % task)\n",
    "            self.simulator.set_task(task=task)\n",
    "        else:\n",
    "            logger.info(\"Setting task %s with task_params %s...\" % (self.task, self.task_params))\n",
    "            self.simulator.set_task_by_name(task_name=self.task, task_params=self.task_params)\n",
    "        logger.info(\"... done\")\n",
    "\n",
    "        if turn_on_lights:\n",
    "            self._turn_on_lights()\n",
    "\n",
    "        init_state = reduce_float_precision(self.simulator.get_current_state().to_dict())\n",
    "\n",
    "        if obs_dir is not None and not os.path.isdir(obs_dir):\n",
    "            os.makedirs(obs_dir)\n",
    "\n",
    "        return api_success, init_state\n",
    "\n",
    "    def _write_last_states_and_frames(self, init_state, obs_dir, target_object_active, write_frames, write_states):\n",
    "        frame_idx = \"end\"\n",
    "        if obs_dir is not None and write_states:\n",
    "            self.write_cur_state(frame_idx, obs_dir, init_state)\n",
    "\n",
    "        if obs_dir is not None and write_frames:\n",
    "            self.write_frames(frame_idx, obs_dir, target_object_active)\n",
    "\n",
    "    def _write_progress_check(self, idx, obs_dir, action_definition, target_object_active):\n",
    "        frames = self.simulator.get_latest_images()\n",
    "        r = self.simulator.apply_progress_check(\n",
    "            action_definition[\"action_name\"],\n",
    "            self.episode.interactions[idx].agent_id,\n",
    "            self.episode.interactions[idx].action.query,\n",
    "        )\n",
    "\n",
    "        # If this was a progress check query, write the observation to file.\n",
    "        if action_definition[\"action_name\"] == \"OpenProgressCheck\":\n",
    "            with open(\n",
    "                os.path.join(\n",
    "                    obs_dir,\n",
    "                    \"progresscheck.status.%s.json\" % str(self.episode.interactions[idx].time_start),\n",
    "                ),\n",
    "                \"w\",\n",
    "            ) as f:\n",
    "                json.dump(r, f)  # Success, subgoal success, string descriptions, problem objects\n",
    "        # Else, this is an oid find or object search that takes a string as input and outputs\n",
    "        # a segmentation mask + actives the target object camera\n",
    "        else:\n",
    "            if not target_object_active:  # write target object frame if we missed it\n",
    "                frames = self.simulator.get_latest_images()\n",
    "                self._write_frame(\n",
    "                    frames[\"targetobject\"],\n",
    "                    os.path.join(\n",
    "                        obs_dir,\n",
    "                        \"targetobject.frame.%s.jpeg\" % str(self.episode.interactions[idx].time_start),\n",
    "                    ),\n",
    "                )\n",
    "            target_object_active = True\n",
    "            with open(\n",
    "                os.path.join(\n",
    "                    obs_dir,\n",
    "                    \"progresscheck.%s.%s.json\"\n",
    "                    % (\n",
    "                        action_definition[\"action_name\"],\n",
    "                        str(self.episode.interactions[idx].time_start),\n",
    "                    ),\n",
    "                ),\n",
    "                \"w\",\n",
    "            ) as f:\n",
    "                # r contains success, oid shown, view pos/rot for topdown map, hotspots info.\n",
    "                # In the video, we'll show whether the search was a success, what was searched for,\n",
    "                # and what oid was shown.\n",
    "                to_report = {\n",
    "                    \"success\": r[\"success\"],\n",
    "                    \"query\": self.episode.interactions[idx].action.query,\n",
    "                }\n",
    "                if \"shown_oid\" in r:\n",
    "                    to_report[\"shown_oid\"] = r[\"shown_oid\"]\n",
    "                json.dump(to_report, f)\n",
    "\n",
    "            # Write targetobject segmentation frame that contains exact segmentation mask for object.\n",
    "            mask_frame = np.zeros_like(frames[\"targetobject\"])\n",
    "            if \"shown_oid\" in r and len(r[\"shown_oid\"]) > 0:\n",
    "                mask_points = np.where(self.simulator.get_target_object_seg_mask(r[\"shown_oid\"])[\"mask\"] == 1)[:2]\n",
    "                for p in mask_points:\n",
    "                    mask_frame[p] = (255, 255, 255)\n",
    "            self._write_frame(\n",
    "                mask_frame,\n",
    "                os.path.join(\n",
    "                    obs_dir,\n",
    "                    \"targetobject.mask.%s.jpeg\" % str(self.episode.interactions[idx].time_start),\n",
    "                ),\n",
    "            )\n",
    "        return target_object_active\n",
    "\n",
    "    def _write_keyboard_frame(self, idx, obs_dir):\n",
    "        with open(\n",
    "            os.path.join(\n",
    "                obs_dir,\n",
    "                \"keyboard.%d.%s.json\"\n",
    "                % (\n",
    "                    self.episode.interactions[idx].agent_id,\n",
    "                    str(self.episode.interactions[idx].time_start),\n",
    "                ),\n",
    "            ),\n",
    "            \"w\",\n",
    "        ) as f:\n",
    "            json.dump(\n",
    "                {\n",
    "                    \"agent_id\": self.episode.interactions[idx].agent_id,\n",
    "                    \"utterance\": self.episode.interactions[idx].action.utterance,\n",
    "                },\n",
    "                f,\n",
    "            )\n",
    "\n",
    "    def _wait_for_real_time(self, idx):\n",
    "        twait = self.episode.interactions[idx].time_start - (\n",
    "            self.episode.interactions[idx - 1].time_start if idx > 0 else 0\n",
    "        )\n",
    "        if twait > 0:\n",
    "            logger.info(\"waiting %.2f seconds\" % twait)\n",
    "            time.sleep(twait)\n",
    "\n",
    "    def _write_frame(self, np_frame_array, filename):\n",
    "        pil_img = Image.fromarray(np_frame_array)\n",
    "        pil_img.save(filename, format=\"jpeg\")\n",
    "\n",
    "    def _turn_on_lights(self):\n",
    "        logger.warn(\"Turning on lights... This should not be used for experiments\")\n",
    "        objects = self.simulator.get_objects()\n",
    "        light_switches = [obj for obj in objects if \"LightSwitch\" in obj[\"objectType\"]]\n",
    "        for obj in light_switches:\n",
    "            action = {\"action\": \"ToggleObjectOn\", \"agentId\": 0, \"objectId\": obj[\"objectId\"], \"forceAction\": True}\n",
    "            self.simulator.controller.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "\n",
    "import argparse\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from teach.inference.actions import all_agent_actions, obj_interaction_actions\n",
    "from teach.inference.teach_model import TeachModel\n",
    "from teach.logger import create_logger\n",
    "\n",
    "class Driver(TeachModel):\n",
    "    \"\"\"\n",
    "    Sample implementation of TeachModel.\n",
    "    Demonstrates usage of custom arguments as well as sample implementation of get_next_actions method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, process_index: int, num_processes: int, model_args: List[str]):\n",
    "        \"\"\" Constructor\n",
    "        :param process_index: index of the eval process that launched the model\n",
    "        :param num_processes: total number of processes launched\n",
    "        :param model_args: extra CLI arguments to teach_eval will be passed along to the model\n",
    "        \"\"\"\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--seed\", type=int, default=1, help=\"Random seed\")\n",
    "        args = parser.parse_args(model_args)\n",
    "\n",
    "        logger.info(f\"SampleModel using seed {args.seed}\")\n",
    "        np.random.seed(args.seed)\n",
    "\n",
    "    def get_next_action(self, img, edh_instance, prev_action, img_name=None, edh_name=None):\n",
    "        \"\"\"\n",
    "        This method will be called at each timestep during inference to get the next predicted action from the model.\n",
    "        :param img: PIL Image containing agent's egocentric image\n",
    "        :param edh_instance: EDH instance\n",
    "        :param prev_action: One of None or a dict with keys 'action' and 'obj_relative_coord' containing returned values\n",
    "        from a previous call of get_next_action\n",
    "        :param img_name: image file name\n",
    "        :param edh_name: EDH instance file name\n",
    "        :return action: An action name from all_agent_actions\n",
    "        :return obj_relative_coord: A relative (x, y) coordinate (values between 0 and 1) indicating an object in the image;\n",
    "        The TEACh wrapper on AI2-THOR examines the ground truth segmentation mask of the agent's egocentric image, selects\n",
    "        an object in a 10x10 pixel patch around the pixel indicated by the coordinate if the desired action can be\n",
    "        performed on it, and executes the action in AI2-THOR.\n",
    "        \"\"\"\n",
    "        action = np.random.choice(all_agent_actions)\n",
    "\n",
    "        #### call forward\n",
    "\n",
    "        obj_relative_coord = None\n",
    "        if action in obj_interaction_actions:\n",
    "            obj_relative_coord = [\n",
    "                np.random.uniform(high=0.99),\n",
    "                np.random.uniform(high=0.99),\n",
    "            ]\n",
    "        return action, obj_relative_coord\n",
    "\n",
    "    def start_new_edh_instance(self, edh_instance, edh_history_images, edh_name=None):\n",
    "        \"\"\"\n",
    "        Since this class produces random actions at every time step, no particular setup is needed. When running model\n",
    "        inference, this would be a suitable place to preprocess the dialog, action and image history\n",
    "        :param edh_instance: EDH instance\n",
    "        :param edh_history_images: List of images as PIL Image objects (loaded from files in\n",
    "                                   edh_instance['driver_image_history'])\n",
    "        :param edh_name: EDH instance file name\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward():\n",
    "        pass\n",
    "\n",
    "\n",
    "class Commander(TeachModel):\n",
    "    \"\"\"\n",
    "    Sample implementation of TeachModel.\n",
    "    Demonstrates usage of custom arguments as well as sample implementation of get_next_actions method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, process_index: int, num_processes: int, model_args: List[str]):\n",
    "        \"\"\" Constructor\n",
    "        :param process_index: index of the eval process that launched the model\n",
    "        :param num_processes: total number of processes launched\n",
    "        :param model_args: extra CLI arguments to teach_eval will be passed along to the model\n",
    "        \"\"\"\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--seed\", type=int, default=1, help=\"Random seed\")\n",
    "        args = parser.parse_args(model_args)\n",
    "\n",
    "        logger.info(f\"SampleModel using seed {args.seed}\")\n",
    "        np.random.seed(args.seed)\n",
    "\n",
    "    def get_next_action(self, img, edh_instance, prev_action, img_name=None, edh_name=None):\n",
    "        \"\"\"\n",
    "        This method will be called at each timestep during inference to get the next predicted action from the model.\n",
    "        :param img: PIL Image containing agent's egocentric image\n",
    "        :param edh_instance: EDH instance\n",
    "        :param prev_action: One of None or a dict with keys 'action' and 'obj_relative_coord' containing returned values\n",
    "        from a previous call of get_next_action\n",
    "        :param img_name: image file name\n",
    "        :param edh_name: EDH instance file name\n",
    "        :return action: An action name from all_agent_actions\n",
    "        :return obj_relative_coord: A relative (x, y) coordinate (values between 0 and 1) indicating an object in the image;\n",
    "        The TEACh wrapper on AI2-THOR examines the ground truth segmentation mask of the agent's egocentric image, selects\n",
    "        an object in a 10x10 pixel patch around the pixel indicated by the coordinate if the desired action can be\n",
    "        performed on it, and executes the action in AI2-THOR.\n",
    "        \"\"\"\n",
    "        action = np.random.choice([\"OpenProgressCheck\", \"\"])\n",
    "\n",
    "        #### call forward\n",
    "\n",
    "        obj_relative_coord = None\n",
    "        if action in obj_interaction_actions:\n",
    "            obj_relative_coord = [\n",
    "                np.random.uniform(high=0.99),\n",
    "                np.random.uniform(high=0.99),\n",
    "            ]\n",
    "        return action, obj_relative_coord\n",
    "\n",
    "    def start_new_edh_instance(self, edh_instance, edh_history_images, edh_name=None):\n",
    "        \"\"\"\n",
    "        Since this class produces random actions at every time step, no particular setup is needed. When running model\n",
    "        inference, this would be a suitable place to preprocess the dialog, action and image history\n",
    "        :param edh_instance: EDH instance\n",
    "        :param edh_history_images: List of images as PIL Image objects (loaded from files in\n",
    "                                   edh_instance['driver_image_history'])\n",
    "        :param edh_name: EDH instance file name\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TATC:\n",
    "    def __init__(self, mode: str, process_index: int, num_processes: int, model_args: List[str]):\n",
    "        self.mode = mode ##train/eval\n",
    "\n",
    "\n",
    "    def run_train(self):\n",
    "        \"\"\"\n",
    "        training loop\n",
    "        \"\"\"\n",
    "        ### decide which agent to run \n",
    "\n",
    "        ## load data\n",
    "        \n",
    "\n",
    "        for epoch in range(info[\"progress\"], self.args.epochs):\n",
    "\n",
    "            for _ in tqdm(range(epoch_length), desc=\"train\"):\n",
    "                # sample batches\n",
    "                \n",
    "                # do the forward passes\n",
    "            \n",
    "                # compute losses\n",
    "               \n",
    "                # do the gradient step\n",
    "\n",
    "                # compute metrics\n",
    "\n",
    "            # save the checkpoint\n",
    "\n",
    "            # dump the training info\n",
    "    \n",
    "\n",
    "    def eval:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f85ee5ef802edbabe18361e4a63b5b7791f6b1c7bc9b4be3b2055c47ed509a97"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
